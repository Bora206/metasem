%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts to Frontiers, it is not mandatory to use frontiers.cls nor frontiers.tex  %
% This will only generate the Manuscript, the final article will be typeset by Frontier after acceptance.                                                 %
%                                                                                                                                                  %
% When submitting your files, remember to upload this *tex file, the pdf generated with it, and all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{metaSEM An R Package for Meta-Analysis using Structural Equation Modeling}

%%% Version 2.4 Generated 2014/03/12 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ yu can find the packages and how to install them, if necessary. %%%

%\documentclass{frontiersENG} % for Engineering articles
\documentclass[a4paper]{article} % for Science articles
%\documentclass{frontiersHLTH} % for Health articles
%\documentclass{frontiersFPHY} % for Physics articles

%\setcitestyle{square}
\usepackage{float} 
\usepackage{amsmath}
\usepackage{natbib}
\usepackage[margin=1.0in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage[pdftex, citecolor=green, urlcolor=cyan]{hyperref}


% Leave a blank line between paragraphs in stead of using \\

\title{\texttt{metaSEM}: An \R{} Package for Meta-Analysis\\ using Structural Equation Modeling}%%% write here for which journal %%%
\author{Mike W.-L. Cheung
\thanks{E-mail: \href{mailto:mikewlcheung@nus.edu.sg}{mikewlcheung@nus.edu.sg}; Website: \url{http://courses.nus.edu.sg/course/psycwlm/internet/}}}
\affil{Department of Psychology,\\ National University of Singapore}

% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
% If one of the authors has a change of address, list the new address below the correspondence details using a superscript symbol and use the same symbol to indicate the author in the author list.
% \def\Address{$^{1}$Department of Psychology, National University of Singapore, Singapore 117570} 
% % The Corresponding Author should be marked with an asterisk
% % Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author
% \def\corrAuthor{Mike W.-L. Cheung}
% \def\corrAddress{Department of Psychology, National University of Singapore, Singapore 117570}
% \def\corrEmail{mikewlcheung@nus.edu.sg}

% \color{FrontiersColor} Is the color used in the Journal name, in the title, and the names of the sections.


%%%%%%%%%%%%%%%%%%%%%%%%%% New commands
\newcommand{\R}[1]{{\textsf{R}}}
\newcommand{\pkg}[1]{\texttt{#1}}
\newcommand{\Rcode}[1]{\texttt{#1}}
\newcommand{\OpenMx}{{\texttt{OpenMx}}}
\newcommand{\metaSEM}{{\texttt{metaSEM}}}
\newcommand{\lavaan}{{\texttt{lavaan}}}
\newcommand{\metafor}{{\texttt{metafor}}}
\newcommand{\E}{\mathsf{E}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\Cov}{\mathsf{Cov}}
\newcommand{\T}{\mathrm{T}}         % \newcommand{\T}{\top} or \intercal
\DeclareMathOperator{\tr}{tr}       % trace operator
\DeclareMathOperator{\Diag}{Diag}   % diagonal operator
\DeclareMathOperator{\vech}{vech}   % for covariance matrix
\DeclareMathOperator{\vechs}{vechs} % for correlation matrix



\begin{document}


\maketitle

<<include=FALSE, echo=FALSE>>=
library(knitr)
opts_chunk$set(echo=TRUE, tidy=FALSE, eval=TRUE)
@

<<Settings, echo=FALSE, eval=TRUE>>=
options(prompt="R> ", continue="   ", width=70, useFancyQuotes = FALSE)
@ 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% The sections below are for reference only. 
%%%
%%% For Original Research Articles, Clinical Trial Articles, and Technology Reports the section headings should be those appropriate for your field and the research itself. It is recommended to organize your manuscript in the
%%% following sections or their equivalents for your field:
%%% Abstract, Introduction, Material and Methods, Results, and Discussion.
%%% Please note that the Material and Methods section can be placed in any of the following ways: before Results, before Discussion or after Discussion.
%%%
%%%For information about Clinical Trial Registration, please go to http://www.frontiersin.org/about/AuthorGuidelines#ClinicalTrialRegistration
%%%
%%% For Clinical Case Studies the following sections are mandatory: Abstract, Introduction, Background, Discussion, and Concluding Remarks.
%%%
%%% For all other article types there are no mandatory sections.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\providecommand{\keywords}[1]{\textbf{\textit{Keywords:}} #1}

\begin{abstract}\footnote{\begin{normalsize}This vignette is a modified version of \cite{cheung_metasem:_2014}, published in \emph{Frontiers in Psychology}. Please cite it if you use the \texttt{metaSEM} package in your publications.\end{normalsize}}
The \texttt{metaSEM} package provides functions to conduct univariate, multivariate, and three-level meta-analyses using a structural equation modeling (SEM) approach via the \texttt{OpenMx} package in the \R{} statistical platform. It also implements the two-stage SEM approach to conducting fixed- and random-effects meta-analytic SEM on correlation or covariance matrices. This paper briefly outlines the theories and their implementations. It provides a summary on how meta-analyses can be formulated as structural equation models. The paper closes with a conclusion on several relevant topics to this SEM-based meta-analysis. Several examples  are used to illustrate the procedures in the supplementary material. 

%%% Leave the Abstract empty if your article falls under any of the following categories: Editorial Book Review, Commentary, Field Grand Challenge, Opinion or specialty Grand Challenge.
% \section{}
%As a primary goal, the abstract should render the general significance and conceptual advance of the work clearly accessible to a broad readership. References should not be cited in the abstract.
%Refer to \\ \url{http://www.frontiersin.org/}\texttt{\journal}\url{/authorguidelines} \\ or \textbf{Table\ref{Tab:01}} for abstract requirement and length according to article type.

% \tiny
\keywords{meta-analysis, structural equation modeling, meta-analytic structural equation modeling, \texttt{metaSEM}, \R{}} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}


\section{Introduction}
Meta-analysis is a popular technique for synthesizing research findings in the social, behavioral, educational, and medical sciences \citep[e.g.,][]{borenstein_introduction_2009, hedges_statistical_1985, schmidt_methods_2015, whitehead_meta-analysis_2002}. There are several standalone programs for conducting meta-analyses, e.g., Comprehensive Meta-Analysis \citep{borenstein_comprehensive_2005}. There are also macros or packages to fit some meta-analytic models in standard statistical packages such as \texttt{SPSS} \citep{lipsey_practical_2000}, and \texttt{SAS} \citep{arthur_conducting_2001}. \R{} \citep{r_development_core_team_r:_2014} is a popular open source statistical platform for computations and data analysis. There are also several \R{} packages available for meta-analysis \citep[e.g.,][]{meta, rmeta, viechtbauer_conducting_2010}.

The \texttt{metaSEM} package \citep{cheung_metasem:_2014} is another \R{} package for conducting meta-analyses. It formulates univariate, multivariate, and three-level meta-analytic models as structural equation models \citep{Cheung:2008, Cheung:2011a, Cheung:2013b, cheung_meta-analysis:_2015} via the \href{http://openmx.psyc.virginia.edu/}{\texttt{OpenMx}} package \citep{OpenMx:2011}. It also implements the two-stage structural equation modeling (TSSEM) approach \citep{Cheung+Chan:2005, Cheung+Chan:2009, cheung_fixed-_2014} to fit fixed- and random-effects meta-analytic structural equation modeling (MASEM) on correlation or covariance matrices. This paper outlines the meta-analytic models implemented in the \texttt{metaSEM} package \citep{cheung_meta-analysis:_2015}. There are two main objectives of this paper. First, it provides an succinct summary on how various meta-analytic models can be formulated as structural equation models. Readers may refer to the references for more details and advantages of formulating meta-analytic models as structural equation models. Second, it illustrates how to conduct these analyses using the \texttt{metaSEM} package. Complete \R{} code, output, and remarks are included in the supplementary material. Users may refer to \url{http://courses.nus.edu.sg/course/psycwlm/Internet/metaSEM/} on how to install the \texttt{metaSEM} package.  

\section{Structural equation modeling based meta-analysis} 
Structural equation modeling is a multivariate technique to fit and test hypothesized models. Let $\mathbf{y}$ be a $p \times 1$ vector of a sample of continuous data from a multivariate normal distribution where $p$ is the number of observed variables. It is hypothesized that the model for the first and the second moments are functions of $\mathbf{\theta}$, where $\mathbf{\theta}$ is a vector of parameters that can be regression coefficients, error variances, factor loadings, and factor variances. The model is: 
\begin{equation}
  \begin{split}
\mathbf{\mu} &= \mathbf{\mu}(\mathbf{\theta}) \quad\mbox{and}\\
\mathbf{\Sigma} &= \mathbf{\Sigma}(\mathbf{\theta}),
  \end{split}
\end{equation}
where $\mathbf{\mu}$ and $\mathbf{\Sigma}$ are the population mean vector and covariance matrix, respectively. Maximum likelihood (ML) estimation method is the most common estimation method in SEM. The -2*log-likelihood ($-2LL$) for the $i$th case is,
\begin{equation}
  \label{llSEM}
-2LL_i(\mathbf{\theta}; \mathbf{y}_i)_\mathrm{ML} = p_i \log(2\pi) + \log|\mathbf{\Sigma}_i(\theta)| + (\mathbf{y}_i - \mathbf{\mu}_i(\theta))^\top \mathbf{\Sigma}_i(\theta)^{-1} (\mathbf{y}_i - \mathbf{\mu}_i(\theta)), 
\end{equation}
where $p_i$ is the number of filtered variables with complete data in the $i$th case, $\mathbf{\mu}_i(\theta)$ and $\mathbf{\Sigma}_i(\theta)$ are the model implied mean vector and the model implied covariance matrix for the $i$th case, respectively. Since there is a subscript $i$ in Equation~\ref{llSEM}, the model implied mean vector and covariance matrix may vary across cases. Thus, it automatically handles incomplete data by selecting the complete data in the log-likelihood function with the full information maximum likelihood (ML or FIML) estimation method \citep{enders_applied_2010}. 

To obtain the parameter estimates, we may take the sum of the $-2LL_i$ over all cases and minimize it. Iterative methods are used to obtain the parameter estimates. When it is convergent, the asymptotic sampling covariance matrix of the parameter estimates may be obtained from the inverse of the Hessian matrix. The standard errors (\textit{SE}s) of the parameter estimates are calculated by taking the square root of the diagonal elements of the asymptotic sampling covariance matrix. The parameter estimates divided by their \textit{SE}s follow a \textit{z} distribution under the null hypothesis. A likelihood ratio (\textit{LR}) statistic may also be used to compare nested models. The model fit and the significance of individual parameters can be tested \citep[e.g.,][]{kline_principles_2011}.

\subsection{Univariate fixed-effects model}
The following subsections briefly introduce how various meta-analytic models can be formulated as structural equation models. Let us begin with the meta-analytic model with only one effect size $y_i$ in the $i$th study \citep{Cheung:2008}. $y_i$ can be any effect size, such as the odds ratio, raw mean difference, standardized mean difference, correlation coefficient, or its Fisher's z transformed score. When the sample sizes in the primary studies are reasonably large, $y_i$ can be assumed to be normally distributed with a variance of $v_i$ \citep[e.g., see][for the formulas of common effect sizes]{borenstein_introduction_2009}. The univariate fixed-effects model for the $i$th study is:
\begin{equation}
y_i = \beta_\mathrm{F}+e_i,
\end{equation}
where $ \beta_\mathrm{F} $ is the common effect under the fixed-effects model, and $\mathrm{Var}(e_i)=v_i$ is the known sampling variance. To conduct a univariate fixed-effects meta-analysis in SEM, we may fit the following model implied moments:
\begin{equation}
  \begin{split}
\mu_i(\mathbf{\theta}) &=\beta_\mathrm{F} \quad\mbox{and}\\
\Sigma_i(\mathbf{\theta}) &=v_i.
  \end{split}
\end{equation}
Since $v_i$ is known, the only parameter in the model is $\beta_\mathrm{F}$. Figure~\ref{fig:01} shows the graphical model of the fixed-effects meta-analysis.

\begin{figure}[h]
\begin{center}
\includegraphics[width=7cm]{Fig1}%
\end{center}
 \textbf{\refstepcounter{figure}\label{fig:01} Figure \arabic{figure}.}{Univariate fixed-effects meta-analysis}
\end{figure}


\subsection{Univariate random-effects model}
Since the primary studies are conducted by different researchers in different settings, these studies are unlikely not direct replicates of each other. It is reasonable to expect that the population effect sizes may not be the same. A random-effects model allows studies to have their own study-specific effect. The model for the $i$th study is:
\begin{equation}
y_i = \beta_\mathrm{R}+ u_i+e_i,
\end{equation}
where $ \beta_\mathrm{R}$ is the average population effect under the random-effects model, and $\mathrm{Var}(u_i)=\tau^2$ is the heterogeneity variance that has to be estimated. To fit the model in SEM, we may consider the following model implied moments:
\begin{equation}
  \begin{split}
\mu_i(\mathbf{\theta}) &=\beta_\mathrm{R} \quad\mbox{and}\\
\Sigma_i(\mathbf{\theta}) &=\tau^2+v_i.
  \end{split}
\end{equation}
In the literature of meta-analysis, $v_i$ and $\tau^2+v_i$ are known as the conditional and the unconditional variances, respectively. Under this model we have to estimate both $\beta_\mathrm{R}$ and $\tau^2$. Figure~\ref{fig:02} shows the graphical model of the random-effects meta-analysis. Various estimation methods, such as methods of moments, ML estimation and restricted maximum likelihood (REML) estimation may be used to estimate $\tau^2$ \citep[e.g.,][]{borenstein_introduction_2009}. The default estimation method in the SEM-based meta-analysis is ML estimation, while the REML estimation method may also be used to minimize the slight negative bias on the estimated variance component using the ML estimation method \citep{Cheung:2013a}.

\begin{figure}
\begin{center}
\includegraphics[width=7cm]{Fig2}%
\end{center}
 \textbf{\refstepcounter{figure}\label{fig:02} Figure \arabic{figure}.}{Univariate random-effects meta-analysis}
\end{figure}

\paragraph{Quantifying heterogeneity}
To test the homogeneity of the population effect sizes, we may compute the \textit{Q} statistic \citep{cochran_combination_1954}, 
\begin{equation}
Q = \sum_{i=1}^k w_i(y_i - \hat{\beta}_\mathrm{F})^2, 
\end{equation}
where $w_i=1/v_i$. Under the null hypothesis of the homogeneity of effect sizes, the $Q$ statistic has an approximate chi-square distribution with $(k-1)$ degrees of freedom ($df$s). The \textit{Q} statistic may be significant simply because of the large number of studies. Conversely, a large \textit{Q} statistic may be non-significant because of the small number of studies. Therefore, the significance of the \textit{Q} statistic should not be used to determine whether a fixed- or a random-effects model is used in the analysis.

One popular index quantifying the degree of heterogeneity of effect sizes is the $I^2$ \citep{higgins_quantifying_2002}. The general formula is 
\begin{equation}
I^2 = \frac{\hat{\tau}^2}{ \hat{\tau}^2 + \tilde{v}}, 
\end{equation}
where $\tilde{v}$ is a \textit{typical} within-study sampling variance. $I^2$ can be interpreted as the proportion of the total variation of the effect size that is due to the between study heterogeneity. \cite{higgins_quantifying_2002} defined the \textit{typical} within-study sampling variance using the \textit{Q} statistic:
\begin{equation}
  \tilde{v}_\mathrm{Q} = \frac{ (k-1) \sum_{i=1}^k 1/v_i  }{ (\sum_{i=1}^k 1/v_i)^2 - \sum_{i=1}^k 1/v_i^2 }. 
\end{equation}
One advantage of using $\tilde{v}_\mathrm{Q}$ as the \textit{typical} within-study sampling variance is that $I^2$ can be simplified to $I^2_\mathrm{Q} = Q - (k-1)/Q$. 

Two more definitions of $\tilde{v}$ have also been proposed in the literature. \cite{takkouche_evaluation_1999} suggested that the harmonic mean of $v_i$ can be used as the \textit{typical} within-study sampling variance,
\begin{equation}
  \tilde{v}_\mathrm{HM} = \frac{k}{ \sum_{i=1}^k 1/v_i }. 
\end{equation}
\cite{xiong_measuring_2010} also discussed an estimator of $I^2$ that is based on the arithmetic mean:
\begin{equation}
  \tilde{v}_\mathrm{AM} = \sum_{i=1}^k v_i/k .
\end{equation}
All of the above definitions are available in the \texttt{metaSEM} package. Users may choose among them by specifying the argument \texttt{I2="I2q"} based on the \textit{Q} statistic (the default), \texttt{I2="I2hm"} based on the harmonic mean, and \texttt{I2="I2am"} based on the arithmetic mean.


\subsection{Univariate mixed-effects model} 
The mixed-effects meta-analysis extends the random-effects meta-analysis by using study characteristics as predictors. Assuming that $\mathbf{x}_i$ is an $(m+1) \times 1$ vector of predictors including a constant of 1 where $m$ is the number predictors in the $i$th study, the mixed-effects model is:
\begin{equation}
y_i = \mathbf{x}^\top_i \mathbf{\beta}  + u_i + e_i,
\end{equation}
where $\mathbf{\beta}$ is a a $(m+1) \times 1$ vector of regression coefficients including the intercept. To fit the model in SEM, we may use the following model implied conditional mean and variance:
\begin{equation}
  \begin{split}
\mu_i(\mathbf{\theta} \vert \mathbf{x}_i ) &= \mathbf{x}^\top_i \mathbf{\beta} \quad\mbox{and}\\
\Sigma_i(\mathbf{\theta} \vert \mathbf{x}_i) &= \tau^2 + v_i.
  \end{split}
\end{equation}
Figure~\ref{fig:03} shows the graphical model of the mixed-effects meta-analysis with one predictor. A phantom variable $P$ is introduced to specify the predictor $\mathbf{x}_i$. Since $\mathbf{x}_i$ is specified via definition variables \citep[see][]{cheung_fixed-effects_2010}, $\mathbf{x}_i$ is treated as a design matrix rather than as variables. 

\begin{figure}[h]
\begin{center}
\includegraphics[width=11cm]{Fig3}%
\end{center}
 \textbf{\refstepcounter{figure}\label{fig:03} Figure \arabic{figure}.}{Univariate mixed-effects meta-analysis with one predictor}
\end{figure}

Mathematically, it is clear that the random-effects meta-analysis is a special case of the mixed-effects meta-analysis by fixing $\mathbf{x}=\mathbf{1}$ as a constant of ones, while the fixed-effects meta-analysis is a special case of the random-effects meta-analysis by fixing $\tau^2=0$. It should be noted that the assumptions and interpretations on the fixed- and random-effects models are different. 

\paragraph{Explained variance}
Besides testing whether the predictors are significant, researchers may want to quantify the degree of prediction. The percentage of variance explained by the inclusion of predictors, 
\begin{equation}
R^2 =\frac{\hat{\tau}^2_0 - \hat{\tau}^2_1}{\hat{\tau}^2_0}, 
\end{equation}
can be calculated by comparing the $\hat{\tau}^2_0$ without a predictor and the $\hat{\tau}^2_1$ with predictors \citep{raudenbush_analyzing_2009}. When the calculated $R^2$ is negative, it is usually truncated to zero.


\subsection{Multivariate meta-analysis} \label{sec:MMA}
When the research questions become more complicated, a single effect size may not be sufficient to summarize the effect in the primary studies. Multiple effect sizes are required to quantify the effect of the studies. Let us assume that there are a total of $p$ effect sizes with $m$ predictors in $k$ studies. Since it is likely that different numbers of effect sizes are reported in the primary studies, we assume that there are $p_i$ effect sizes in the $i$th study. The model for the multivariate mixed-effects meta-analysis in the $i$th study is:
\begin{equation} 
\mathbf{y}_i = \mathbf{B}_i \mathbf{x}_i  + \mathbf{Z}_i \mathbf{u}_i + \mathbf{e}_i ,
\end{equation}
where $\mathbf{y}_i$ is a $p_i \times 1$ vector of effect sizes, $\mathbf{B}_i$ is a $p_i \times (m$+1) matrix of regression coefficients including the intercepts, $\mathbf{x}_i$ is a ($m+1) \times 1$ matrix of predictors including 1 in the first column, $\mathbf{Z}_i$ is a $p_i \times p$ filter matrix selecting the effect sizes that are present, $\mathbf{u}_i$ is a $p \times1$ study-specific random effects, and $\mathbf{e}_i$ is a $p_i \times 1$ sampling error. 

We assume that $\mathrm{Var}(\mathbf{e}_i)=\mathbf{V}_i$ is known in the $i$th study and that $\mathrm{Var}(\mathbf{u}_i)=\mathbf{T}^2$ is the variance component of the between-study heterogeneity that has to be estimated. The model handles missing effect sizes by selecting the complete effect sizes only in the above equation. Since $\mathbf{x}_i$ is a design matrix, missing value is not allowed in $\mathbf{x}_i$. When there are missing values in $\mathbf{x}_i$, the whole study will be deleted before the analysis is conducted. 

The $-2LL$ of the above model is:
\begin{equation} 
\begin{split}
-2LL_i(\mathbf{B}, \mathbf{T}^2; \mathbf{y}_i)_\mathrm{ML} = & p_i*\log(2\pi) + \log| \mathbf{Z}_i \mathbf{T}^2 \mathbf{Z}_i^{\top} +\mathbf{V}_i| + \\ & (\mathbf{y}_i - \mathbf{B}_i \mathbf{x}_i)^{\top} (\mathbf{Z}_i \mathbf{T}^2 \mathbf{Z}_i^{\top} +\mathbf{V}_i)^{-1} (\mathbf{y}_i - \mathbf{B}_i \mathbf{x}_i).
\end{split}
\end{equation}
To fit the multivariate mixed-effects meta-analysis in SEM, we use the following model implied conditional mean vector and covariance matrix \citep{Cheung:2011a}:
\begin{equation}
  \begin{split}
\mathbf{\mu}_i(\mathbf{\theta} \vert \mathbf{x}_i ) &= \mathbf{B}_i \mathbf{x}_i \quad\mbox{and}\\
\mathbf{\Sigma}_i(\mathbf{\theta} \vert \mathbf{x}_i) &= \mathbf{Z}_i \mathbf{T}^2 \mathbf{Z}_i^{\top} +\mathbf{V}_i.
  \end{split}
\end{equation}
Figure~\ref{fig:04} shows the graphical model of the multivariate mixed-effects meta-analysis with two effect sizes per study and one predictor. A phantom variable $P$ is introduced to specify the predictor $\mathbf{x}_i$. 

\begin{figure}[h]
\begin{center}
\includegraphics[width=13cm]{Fig4}%
\end{center}
 \textbf{\refstepcounter{figure}\label{fig:04} Figure \arabic{figure}.}{Multivariate mixed-effects meta-analysis with two effect sizes per study and one predictor}
\end{figure}


The multivariate random-effects meta-analysis is a special case of the multivariate mixed-effects meta-analysis by using $\mathbf{X}_i=1$ as the design matrix; the random-effects meta-analysis is a special case of the fixed-effects meta-analysis by fixing $\mathbf{T}^2=\mathbf{0}$. Moreover, the univariate meta-analysis is also a special case of the multivariate meta-analysis with only one effect size. The $I^2$ and $R^2$ in a univariate meta-analysis may also be calculated for each effect size in a multivariate meta-analysis.


\subsection{Three-level meta-analysis}
Effect sizes are assumed to be independent in most meta-analytic models. However, the effect sizes can be non-independent for various reasons. For example, the effect sizes reported in the same study may be more similar than the effect sizes reported in other studies. When the degree of dependence is known, the multivariate meta-analysis introduced in the Section~\ref{sec:MMA} can be used to model the dependence. When the degree of dependence is not known, a three-level meta-analytic model may be used to address the dependence among the effect sizes \citep[e.g.,][]{Cheung:2013b, konstantopoulos_fixed_2011, van_den_noortgate_three-level_2013}. The model is:
\begin{equation}
y_{ij} =  \mathbf{x}^{\top}_{ij} \mathbf{\beta} + u_{(2)ij} + u_{(3)j} +  e_{ij},
\end{equation}
where $y_{ij}$ is the effect size for the $i$th effect size in the $j$th cluster, $\mathbf{\beta}$ is an $(m+1) \times 1$ vector of regression coefficients including the intercept, $\mathbf{x}_{ij}$ is the $(m+1) \times 1$ predictors including 1 in the first element for the $i$th study at the $j$th cluster, $u_{(2)ij}$ and  $u_{(3)j}$ are the random effects at level 2 and level 3, respectively, and $\mathrm{Var}(e_{ij})=v_{ij}$ is the known sampling variance of the effect size. 

To fit the three-level meta-analytic model in SEM, we may use the following model implied moments for the conditional mean and variance:
\begin{equation}
  \begin{split}
\mathbf{\mu}_{ij}(\mathbf{\theta} \vert \mathbf{x}_{ij} ) &= \mathbf{x}^{\top}_{ij} \mathbf{\beta} \quad\mbox{and}\\
\mathbf{\Sigma}_{ij}(\mathbf{\theta} \vert \mathbf{x}_{ij}) &= \tau^2_{(2)} +  \tau^2_{(3)}  + v_{ij},
  \end{split}
\end{equation}
where $\mathrm{Var}(u_{(2)ij})=\tau^2_{(2)}$ and  $\mathrm{Var}(u_{(3)j})=\tau^2_{(3)}$ are the heterogeneity at level 2 and level 3, respectively \citep{Cheung:2013b}. 

\paragraph{Quantifying heterogeneity and explained variance}
Similar to the $I^2$ defined in a random-effects meta-analysis, we may define the degree of heterogeneity for a three-level meta-analysis in level 2 and level 3 as, 
\begin{equation}
  \begin{split}
I^2_{(2)} &= \frac{\hat{\tau}^2_{(2)}}{\hat{\tau}^2_{(2)} + \hat{\tau}^2_{(3)} + \tilde{v}} \quad\mbox{and}\\
I^2_{(3)} &= \frac{\hat{\tau}^2_{(3)}}{\hat{\tau}^2_{(2)} + \hat{\tau}^2_{(3)} + \tilde{v}},
  \end{split}
\end{equation}
where $\tilde{v}$ is the \textit{typical} within-study sampling variance defined in a random-effects meta-analysis. $I^2_{(2)}$ and $I^2_{(3)}$ can be interpreted as the proportion of the total variation of the effect size that is due to the level 2 and level 3, respectively. Since $\tilde{v}$ is sample specific, one limitation of $I^2_{(2)}$ and $I^2_{(3)}$ is that they are not estimating any population quantities. \cite{Cheung:2013b} introduced two intra-class correlations (\textit{ICC}s),
\begin{equation}
  \begin{split}
ICC_{(2)} &= \frac{\hat{\tau}^2_{(2)}}{\hat{\tau}^2_{(2)} + \hat{\tau}^2_{(3)}} \quad\mbox{and}\\
ICC_{(3)} &= \frac{\hat{\tau}^2_{(3)}}{\hat{\tau}^2_{(2)} + \hat{\tau}^2_{(3)}}.
  \end{split}
\end{equation}
Both $ICC_{(2)}$ and $ICC_{(3)}$ are estimating their population counterparts $\tau^2_{(2)}/(\tau^2_{(2)} + \tau^2_{(3)})$ and $\tau^2_{(3)}/(\tau^2_{(2)} + \tau^2_{(3)})$, respectively. $ICC_{(2)}$ and $ICC_{(3)}$ can be interpreted as the percentage of the population heterogeneity due to level 2 and level 3, respectively.

When there are predictors, we may calculate the $R^2$ for level 2 and level 3 in a similar manner to that defined before, 
\begin{equation}
  \begin{split}
R^2_{(2)} &= \frac{\hat{\tau}^2_{(2)0} - \hat{\tau}^2_{(2)1}}{\hat{\tau}^2_{(2)0}} \quad\mbox{and}\\
R^2_{(3)} &= \frac{\hat{\tau}^2_{(3)0} - \hat{\tau}^2_{(3)1}}{\hat{\tau}^2_{(3)0}}.
  \end{split}
\end{equation}
When the estimates are negative, they are usually truncated to zero.


\section{Meta-analytic structural equation modeling}
Structural equation modeling is a popular modeling techniques in the social and behavioral sciences. When there are more and more studies addressing similar research questions using similar variables, there is a need to compare and synthesize these findings. MASEM combines ideas of meta-analysis and SEM by pooling correlation (or covariance) matrices and testing structural equation models on the pooled correlation (or covariance) matrix \citep[e.g.,][]{becker_model-based_2009, Cheung+Chan:2005, viswesvaran_theory_1995}. There are two stages in conducting the analysis. In the first stage of the analysis, the correlation (or covariance) matrices are pooled together. In the second stage of the analysis, the pooled correlation (or covariance) matrix is used to fit structural equation models.

\cite{Cheung+Chan:2005, Cheung+Chan:2009} proposed a fixed-effects TSSEM. The fixed-effects TSSEM approach has been extended to the random-effects TSSEM by \cite{cheung_fixed-_2014}. Regardless of whether a fixed- or a random-effects model is used, the \texttt{metaSEM} package handles this automatically. In other words, parameter estimates, \textit{SE}s, and goodness-of-fit indices in the stage 2 analysis have already taken the stage 1 model into account.

\subsection{Stage 1 analysis}
The main objective of the stage 1 analysis is to pool the correlation (or covariance) matrices together. There are two classes of models in meta-analysis---fixed-effects models and random-effects models \citep[see][]{hedges_fixed-_1998, schmidt_fixed-_2009}. Fixed-effects models are used for conditional inferences based on the selected studies. They are intended to draw conclusions on the studies included in the meta-analysis. Researchers are mainly interested in the studies used in the analysis. The assumption in fixed-effects models is usually, but not always, that all studies share common effect sizes. The stage one analysis in both the fixed- and the random-effects TSSEM is based on the ML estimation method. Thus, the parameter estimates are unbiased and efficient when the missing correlation coefficients are missing completely at random (MCAR) or missing at random (MAR) \citep[e.g.,][]{enders_applied_2010}.

\subsubsection{Fixed-effects model}
Under the fixed-effects (or more correctly the common effects) model, it is assumed that the population correlation (or covariance) matrices are the same while there are study-specific correlation (or covariance matrices) under the random-effects model. To simplify the presentation, I will mainly focus on the analysis of correlation matrices. Generalizing to analysis of covariance matrices is a straight-forward process \citep[see][]{Cheung+Chan:2009}. A covariance matrix in the $i$th study can be decomposed into a product of the matrices of correlations and standard deviations:
\begin{equation}
  \Sigma_i(\theta) = \mathbf{D}_i \mathbf{P}_i \mathbf{D}_i,
\end{equation}
where $\Sigma_i(\theta)$ is the model implied covariance matrix, $\mathbf{D}_i$ is the diagonal matrix of standard deviations, and $\mathbf{P}_i$ is the correlation matrix. Under the assumption of the homogeneity of correlation matrices, we may obtain a common correlation matrix by imposing the constraint $P=P_1=P_2=\ldots=P_k$, where $D_i$ may vary across studies. When there are missing correlations, the missing data are filtered out. If we want to obtain a common covariance matrix under the assumption of the homogeneity of covariance matrices, we may also add the constraint $D=D_1=D_2=\ldots=D_k$.

An \textit{LR} statistic can be used to test the null hypothesis of homogeneity of correlation matrices $P_1=P_2=\ldots=P_k$. Moreover, various goodness-of-fit indices may also be used to evaluate the appropriateness of the "close" fit of the homogeneity of correlation matrices.

\subsubsection{Random-effects model}
Since the primary studies are independently conducted by different researchers, the samples, measures and research focuses are likely different. The assumption of homogeneity of correlation matrices may not be reasonable. A random-effects TSSEM is usually more appropriate to analyze the data \citep{cheung_fixed-_2014}. When a random-effects model is used, the correlation  matrices are treated as vectors of multivariate effect sizes. Let  $\mathbf{r}_i=\mathrm{vechs}(\mathbf{R}_i)$ be the $p(p-1)/2 \times 1$ vector of a sample correlation for $p$ variables by taking the column-wise non-redundant elements from $\mathbf{R}_i$. If an analysis of the covariance matrices is conducted, the $p(p+1)/2 \times 1$ vectorized multivariate effect sizes become $\mathbf{s}_i=\mathrm{vech}(\mathbf{S}_i)$. 

The model for the sample correlation vector $\mathbf{r}_i$ is:
\begin{equation}
  \mathbf{r}_i = \mathbf{\rho}_{\mathrm{R}} + \mathbf{u}_i + \mathbf{e}_i ,
\end{equation}
where $\rho_{\mathrm{R}}$ is the $p(p-1)/2 \times 1$ vector of average population correlation vector under a random-effects model, $\mathrm{Var}(\mathbf{u}_i)=\mathbf{T}^2$ is the variance components of the random effects, and $\mathrm{Var}(\mathbf{e}_i)=\mathbf{V}_i$ is the known conditional sampling covariance matrix. The multivariate random-effects meta-analysis introduced in Section~\ref{sec:MMA} may be used to conduct the stage 1 analysis with a random-effects model.

When there are many variables or not enough data (studies) in the analysis, $\hat{\mathbf{T}}^2$ can be non-positive definite. The results cannot be trusted. One workaround is to fix $\mathbf{T}^2$ to a diagonal matrix rather than as a symmetric matrix. This can be done easily by specifying the argument \texttt{RE.type="Diag"} when calling the \texttt{tssem1()} function.

\subsection{Stage 2 analysis}
After the stage 1 analysis with either a fixed- or a random-effects model, a vector of pooled correlations $\mathbf{r}$ and its asymptotic covariance matrix $\mathbf{V}$ are available after the analysis. It should be noted that $\hat{\mathbf{T}}^2$ is not directly involved in fitting the correlation structure in the stage 2 analysis. However, the presence of $\mathbf{T}^2$ is required so that the heterogeneity of the random effects has been properly taken in the stage 1 analysis. 

Most applications of MASEM use the pooled correlation matrix as if it was an observed correlation matrix to fit structural equation models. \cite{Cheung+Chan:2005} discussed some of these problems. For example, the elements of the pooled correlation matrix are usually based on different studies. Researchers usually use an ad-hoc sample size, such as the harmonic or arithmetic means of the individual sample sizes, as the sample size in fitting structural equation models. Unless all the correlation coefficients are based on the same number of studies, the precision of some correlation coefficients are over-estimated while others are under-estimated. Another issue is that the pooled correlation matrix is analyzed as it was a covariance matrix. It is generally incorrect to analyze the correlation matrix in SEM, although most published articles using MASEM have treated the pooled correlation matrix as a covariance matrix. Many SEM experts \citep[e.g.,][]{cudeck_analysis_1989} have warned about the problems of analyzing the correlation matrix instead of the covariance matrix in primary-research applications of SEM. Specifically, the chi-square statistics and (or) the \textit{SE}s of parameter estimates may be incorrect.

The TSSEM approach addresses these issues. The weighted least square (WLS) estimation is used to fit the proposed models in the stage 2 analysis. A correlation structural model $\rho(\hat{\gamma})$ is fitted with the WLS estimation method by minimizing the following fit function,
\begin{equation}
  F(\hat{\gamma}) = (\mathbf{r} - \rho(\hat{\gamma}))^\top \mathbf{V}^{-1} (\mathbf{r} - \rho(\hat{\gamma})).
\end{equation}
An \textit{LR} statistic and various goodness-of-fit indices may be used to judge whether the proposed structural model is appropriate, while \textit{SE}s may be used to test the significance of individual parameter estimates.

\section{Illustrations with \R{}} 
Several examples are used to demonstrate the procedures of fitting various meta-analyses and meta-analytic structural equation modeling (MASEM) using the \metaSEM{} package implemented in \R{}. All the data sets are stored in the \metaSEM{} package. We may access the data by calling \Rcode{library("metaSEM")} in \R{}.

\subsection{Univariate meta-analysis}

\subsubsection{Example 1}
\cite{becker_influence_1983} reported 10 studies on sex differences in conformity using the fictitious norm group paradigm. \texttt{di} and \texttt{vi} are the standardized mean difference and its sampling variance, respectively. \texttt{percentage} and \texttt{items} are the percentage of male authors and the number of items, respectively. We need to load the \metaSEM{} package before calling the functions in the package. 
<<UMA0, echo=TRUE, message=FALSE>>=
## Load the library
library("metaSEM")

## Display the content of the data
Becker83                 
@ 

\paragraph{Univariate random-effects model}

The function \texttt{meta()} is used to conduct the univariate and multivariate meta-analyses. The arguments \texttt{y} and \texttt{v} are used to specify the effect sizes and their sampling variances, respectively. By default, a random-effects meta-analysis is fitted. After running the analysis, \texttt{summary()} is used to extract the results. 

<<UMA1, echo=TRUE>>=
summary( meta(y=di, v=vi, data=Becker83) )
@ 
Before interpreting the results, we must check whether the optimization was successful. The \texttt{OpenMx status1} returns the status from the optimizer. The optimization can be considered to be fine if the code is either 0 or 1. Users may refer to \href{http://openmx.psyc.virginia.edu/wiki/errors}{OpenMx's Common Errors (and how to avoid them)} for more details. From the output, the $Q$ statistic $(df=9)$ is 30.65, $p<0.001$. The estimated heterogeneity variance is 0.0774, while the $I^2$ based on the \textit{Q} statistic is 0.67. The average effect size with its 95\% Wald confidence interval (CI) based on the random-effects model is 0.1747 (-0.0475, 0.3969). 

\paragraph{Univariate mixed-effects model}
Following \citep{becker_influence_1983}, we may conduct a mixed-effects meta-analysis by including \texttt{log(items)} as a moderator. The argument \texttt{x} is used to specify the predictors. The estimated regression coefficients are represented by the \texttt{Slopei\_j} parameter, where $i$ and $j$ represent the $i$th effect size and the $j$th predictor in the output. 

<<UMA2, echo=TRUE>>=
summary( meta(y=di, v=vi, x=log(items), data=Becker83) ) 
@ 
The result shows that \texttt{log(items)} is a significant predictor with the estimated regression coefficient and its 95\% Wald CI of 0.211 (0.123, 0.299) with $R^2=1$. This suggests that the effect sizes in the studies become larger when there are more items used to measure the constructs. 

\paragraph{Univariate fixed-effects model}
Mathematically, the fixed-effects meta-analysis is a special case of the random-effects meta-analysis by fixing the heterogeneity variance of the random-effects at 0. The argument \texttt{RE.constraints} is used to constrain the variance component of the random effects. The following analysis shows that the estimated common effect and its 95\% Wald CI under a fixed-effects model is 0.1006 (-0.0180, 0.2192).
<<UMA3, echo=TRUE>>=
summary( meta(y=di, v=vi, data=Becker83, RE.constraints=0) ) 
@ 

\subsubsection{Example 2}
\citet[][]{jaramillo_meta-analysis_2005} conducted a meta-analysis of 61 studies on the relationship between organizational commitment and salesperson job performance. The effect size was a correlation coefficient. \citet{jaramillo_meta-analysis_2005} corrected for unreliability before conducting the analysis. As an illustration, we use the uncorrected correlation coefficients here. The effect size and its sampling variance are \Rcode{r} and \Rcode{r\_v}, respectively.
<<Jaramillo1, echo=TRUE>>=
## Show the first few cases
head(Jaramillo05)
@
 
\paragraph{Random-effects model}
We employ a random-effects model with the following syntax. By default, the $I^2$ is calculated based on the $Q$ statistic (with the \Rcode{I2="I2q"} argument in calling the \Rcode{meta()} function). Readers can also use either the harmonic mean (\Rcode{I2="I2hm"}) or the arithmetic mean (\Rcode{I2="I2am"}) of the sampling variances to calculate the $I^2$.
<<Jaramillo3, eval=TRUE>>=
summary( meta(y=r, v=r_v, data=Jaramillo05) )
@

The homogeneity test of effect sizes is statistically significant with $Q(df=60)=339.4, p< 0.001$. The $\hat{\tau}^2 = .0170$ and $I^2= 0.81$. These indicate that there is a high degree of heterogeneity. The between-study effect explains 81\% of the total variation. The estimated average population correlation coefficient (with its 95\% Wald CI) based on a random-effects model is 0.1866 (0.1487, 0.2245). 

\paragraph{Likelihood-based CI}
The above CIs are based on the Wald approximation (labelled as a \Rcode{z statistic approximation} in the output). When the number of studies is small, LBCI (labelled as a \Rcode{Likelihood-based statistic} in the output) is preferred \citep[e.g.,][]{Cheung:2009a, Neale+Miller:1997}. We may request the LBCI by specifying the \Rcode{intervals.type="LB"} argument. Since $I^2$ is a function of $\hat{\tau}^2$, LBCI on $I^2$ is also reported. The 95\% LBCIs on $\hat{\tau}^2$ and $I^2$ are (0.0106, 0.0276), and (0.732, 0.880), respectively.
<<Jaramillo5, eval=TRUE>>=
summary( meta(y=r, v=r_v, data=Jaramillo05, intervals.type="LB") )
@  


\paragraph{Mixed-effects model}
The moderators can be included by specifying the \Rcode{x} argument in the \Rcode{meta()} function. When there is more than one moderators, they can be combined using the \Rcode{cbind()} command. The explained variance $R^2$ on the effect size is also reported.

The dataset includes the coefficient alpha of the scales on measuring organizational commitment and job performance (\Rcode{OC\_alpha} and \Rcode{JP\_alpha} in the dataset). As an illustration, we include both \Rcode{OC\_alpha} and \Rcode{JP\_alpha} as the moderators. 
<<Jaramillo9, eval=TRUE>>=
## Label this model as "Unequal coefficients"
model1 <- meta(y=r, v=r_v, x=cbind(OC_alpha, JP_alpha), 
               data=Jaramillo05,
               model.name="Unequal coefficients")
summary(model1)
@ 

The estimated regression coefficients for \Rcode{OC\_alpha} and \Rcode{JP\_alpha} (\Rcode{Slope1\_1} and \Rcode{Slope1\_2} in the output) are $\hat{\beta}_\mathrm{OC_{alpha}}=0.1311$, $SE_\mathrm{OC_{alpha}}=0.4587$, $p_\mathrm{OC_{alpha}}=0.7750$, and $\hat{\beta}_\mathrm{JP_{alpha}}=0.8044$, $SE_\mathrm{JP_{alpha}}=0.4304$, $p_\mathrm{JP_{alpha}}=0.0616$, respectively. Neither of them is statistically significant at $\alpha=0.05$ and the $R^2=0$. Therefore, there is no evidence indicating that the reliabilities of the measures are correlated with the effect size. 

Although both coefficients are non-significant in the above analysis, we test $H_0: \beta_\mathrm{equal}=\beta_\mathrm{OC_{alpha}} = \beta_\mathrm{JP_{alpha}}$ as an illustration. First, we need to fit a model with an equality constraint on the regression coefficients by specifying the \Rcode{coef.constraints} argument. The argument expects a $p \times m$ matrix, where $p$ is the number of effect sizes and $m$ is the number of predictors. In this example, it is $1 \times 2$ matrix, where the first and second elements refer to the regression coefficients of \Rcode{OC\_alpha}, and \Rcode{JP\_alpha}, respectively. 

We may impose the equality constraint by using the same label in the constraint. In this example, \Rcode{0*} represents the starting value for the regression coefficients while \Rcode{Slope\_equal} is the name of both coefficients. We further call this model \Rcode{model.name="Equal slopes"} for ease of comparison and save the results to an \R{} object called \Rcode{model2}. 
<<Jaramillo11a, eval=TRUE>>=
( constraint <- matrix(c("0*Slope_equal", "0*Slope_equal"), 
                         nrow=1, ncol=2) )
@ 
<<Jaramillo11b, eval=TRUE>>=
model2 <- meta(y=r, v=r_v, x=cbind(OC_alpha, JP_alpha), 
               data=Jaramillo05, coef.constraints=constraint, 
               model.name="Equal coefficients")
summary(model2)
@

The estimated constrained regression coefficient is $\hat{\beta}_\mathrm{equal}=0.4863, SE_\mathrm{equal}=0.2953, p_\mathrm{equal}=0.10$, which is still non-significant. To test $H_0: \beta_\mathrm{OC_{alpha}} = \beta_\mathrm{JP_{alpha}}$, we compare \Rcode{model1} against \Rcode{model2} with the \Rcode{anova()} function.
<<Jaramillo11, echo=TRUE, eval=TRUE>>=
anova(model1, model2)
@

The \textit{LR} statistic is $\Delta \chi^2(df=1)= 0.9943, p = 0.3187$. Therefore, there is not enough evidence to reject the null hypothesis of equal regression coefficients.  

\paragraph{Testing categorical predictors}
There are three types of samples in the data set: \Rcode{sales}, \Rcode{nonsales}, and \Rcode{mixed} in the variable \Rcode{Sales}. A typical approach is to use one group, say \Rcode{nonsales}, as the reference group and create two dummy variables ($\mathbf{D}_\mathrm{sales}$ and $\mathbf{D}_\mathrm{mixed}$) with only 0 and 1 for \Rcode{sales} and \Rcode{mixed} to represent the differences between these groups to the reference group, the \Rcode{nonsales}. The model is:
\begin{equation}
  \mathbf{y} = \beta_0 + \beta_1 \mathbf{D}_\mathrm{sales} + \beta_2 \mathbf{D}_\mathrm{mixed} + \mathbf{u} + \mathbf{e}, 
\end{equation}
where $\beta_0$ is the population effect size for \Rcode{nonsales}, $\beta_1$ is the difference between \Rcode{sales} and \Rcode{nonsales}, and $\beta_2$ is the difference between \Rcode{mixed} and \Rcode{nonsales}. 

Although the model can be used to test the differences among the groups, it does not provide the estimates for all groups. An alternative approach is to create three indicator variables. We may fit a model without an intercept:
\begin{equation}
  \mathbf{y} = \beta_1 \mathbf{D}_\mathrm{sales} + \beta_2 \mathbf{D}_\mathrm{mixed} + \beta_3 \mathbf{D}_\mathrm{nonsales} + \mathbf{u} + \mathbf{e}, 
\end{equation}
where $\beta_1$, $\beta_2$, and $\beta_3$ now represent the average population effect sizes for \Rcode{sales}, \Rcode{mixed}, and \Rcode{nonsales}, respectively. In order to estimate the means for all three groups, the intercept must be fixed at 0; otherwise, the model is not identified. To test whether all group means are the same, we compare the above model against the intercept model. Under the null hypothesis $H_0: \beta_1=\beta_2=\beta_3$, the test statistic has a chi-square distribution with $df=2$.

First, we show the frequency table of the variable \Rcode{Sales}. Then, we create three indicator variables by using the \Rcode{ifelse()} command.
<<Jaramillo14, echo=TRUE, eval=TRUE>>=
table(Jaramillo05$Sales)
sales <- ifelse(Jaramillo05$Sales=="sales", yes=1, no=0)
nonsales <- ifelse(Jaramillo05$Sales=="nonsales", yes=1, no=0)
mixed <- ifelse(Jaramillo05$Sales=="mixed", yes=1, no=0)
@
To fit the model without an intercept, we fix the intercept at 0 by specifying the \Rcode{intercept.constraints=0} argument. Since the original starting values assume that there is an intercept, there were estimation problems in the model without the intercept. We provide starting values for the regression coefficients by using the \Rcode{coef.constraints} argument:
<<Jaramillo15a, eval=TRUE>>=
( startvalues <- matrix(c("0*Slope1_1", "0*Slope1_2", 
                          "0*Slope1_3"), nrow=1, ncol=3) )
@ 
<<Jaramillo15b, eval=TRUE>>=
model3 <- meta(y=r, v=r_v, x=cbind(sales, mixed, nonsales), 
               data=Jaramillo05, coef.constraints=startvalues,
               intercept.constraints=0,               
               model.name="Indicator variables")
summary(model3)
@

The estimated average effects and their 95\% Wald CIs for the \Rcode{sales}, \Rcode{mixed}, and \Rcode{nonsales} are 0.2283 (0.1742, 0.2824), 0.1466 (0.0226, 0.2706), and 0.1520 (0.0972, 0.2067), respectively. All of them are statistically significant at $\alpha=.05$.

When the null hypothesis $H_0: \beta_1 = \beta_2 = \beta_3$ is true, this model is equivalent to the model with only an intercept. Since the model with only an intercept \Rcode{model4} is nested within the model with predictors \Rcode{model3}, we compare them with the following code:.
<<Jaramillo17, echo=TRUE, eval=TRUE>>=
model4 <- meta(y=r, v=r_v, data=Jaramillo05,
               model.name="Null hypothesis")
anova(model3, model4)
@ 
The \textit{LR} statistic is $\Delta \chi^2(df=2)= 4.1140, p = 0.1278$. Therefore, there is not enough evidence to reject the null hypothesis of equal population correlations. When there are missing values in the moderators, effect sizes with the missing values are deleted before conducting the analyses. The numbers of studies may be different in model comparisons. Users must make sure that the same studies are used in the model comparisons.

\subsection{Multivariate meta-analysis}

\subsubsection{Example 1}
This data set was adapted from \cite{berkey_metaanalysis_1998} that compared surgical and non-surgical treatments for medium-severity periodontal disease one year after treatment. The effect sizes are \texttt{PD}, and \texttt{AL}, while their sampling variance-covariance matrix is \texttt{var\_PD}, \texttt{cov\_PD\_AL}, and \texttt{var\_AL}. A multivariate meta-analysis can be fitted by specifying the multivariate effect sizes and their sampling covariance matrix in the arguments \texttt{y} and \texttt{v} with \texttt{cbind()}, respectively. Only the lower triangle of the sampling covariance matrix arranged by the column major is used in \texttt{v}. For example, if there are three effect sizes and $\mathbf{V}_i= 
\left[ {\begin{array}{ccc}
 V_{11} & \\
 V_{21} & V_{22} \\
 V_{31} & V_{32} & V_{33} \\
 \end{array} } \right] $, we may use \texttt{meta(y=cbind(y1,y2,y3), v=cbind(V11,V21,V31,V22,V32,V33))}. The following syntax conducts a multivariate random-effects meta-analysis on \texttt{Berkey98}:

\paragraph{Multivariate random-effects model}
<<meta_analysis4, echo=TRUE>>=
## Display the content of the data
Berkey98

summary( meta(y=cbind(PD,AL), v=cbind(var_PD,cov_PD_AL,var_AL), 
              data=Berkey98, model.name="Random effects model") )
@ 
The $Q$ statistic $(df=8)$ of the above example is 128.2, $p<0.001$. The estimated variance component is 
$\left[ {\begin{array}{cc}
 0.0070 & \\
 0.0095 & 0.02614 \\
 \end{array} } \right] $. The $I^2$ based on the $Q$ statistic for $PD$ and $AL$ are .6021 and .9250, respectively. The pooled effect sizes with their 95\% Wald CIs based on the random-effects model for $PD$ and $AL$ are 0.3448 (0.2397, 0.4500), and -0.3379 (-0.4972, -0.1787), respectively. 


\paragraph{Multivariate mixed-effects model}
As an illustration, we use \texttt{pub\_year} as a predictor. To make the intercept more interpretable, we center the publication year at 1979, the first year of publication recorded in the data set. 
<<meta_analysis5a, echo=TRUE>>=
mult2 <- meta(y=cbind(PD,AL), v=cbind(var_PD,cov_PD_AL,var_AL), 
              data=Berkey98, x=scale(pub_year,center=1979), 
              model.name="No constraint")
summary(mult2)
@ 
The estimated regression coefficients and their 95\% CIs on $PD$ and $AL$ are 0.0064 (-0.2050, 0.2177), and -0.0706 (-0.3883, 0.2471), respectively. The $R^2$ for predicting $PD$ and $AL$ are 0.0000, and 0.0433, respectively. 

When there are multiple effect sizes, it is preferable to test the significance of all effect sizes simultaneously. We may formulate two nested models and compare them with the \texttt{anova()} function. The following analysis indicates that the likelihood ratio ($LR$) statistic for comparing both regression coefficients is $\chi^2(df=2)=0.3273, p=0.8490$. Thus, the null hypothesis that both regression coefficients are zero is not rejected.

<<meta_analysis5b, echo=TRUE>>=
## Coefficients are fixed at 0 for both effect sizes
mult0 <- meta(y=cbind(PD,AL), v=cbind(var_PD,cov_PD_AL,var_AL), 
              data=Berkey98, x=scale(pub_year,center=1979), 
              model.name="Fixed at 0",
              coef.constraints=matrix(c("0","0"),nrow=2)) 
summary(mult0)

## Compare two models with an LR statistic
anova(mult2, mult0)      
@ 


\paragraph{Multivariate fixed-effects model}
A multivariate fixed-effects meta-analysis is a special case of the random effects meta-analysis by fixing the variance component at a zero matrix. The pooled effect sizes with their 95\% Wald CIs based on the fixed-effects model for $PD$ and $AL$ are 0.3072 (0.2512, 0.3632), and -0.3944 (-0.4310, -0.3578), respectively. It should be noted that the CIs on a fixed-effects model are usually shorter than those on a random-effects model when the heterogeneity is ignored in the analysis.

<<meta_analysis6, echo=TRUE>>=
summary( meta(y=cbind(PD,AL), v=cbind(var_PD,cov_PD_AL,var_AL), 
         RE.constraints=matrix(0,nrow=2,ncol=2), data=Berkey98,
         model.name="Fixed effects model") )  
@

Although we may compare the fixed-effects model (without constraints) and the random-effects model (without any constraint) with a \textit{LR} statistic, the \textit{p} is too conservative. It is because it is testing on the boundary \citep[e.g.,][]{stoel_likelihood_2006}.

\paragraph{Plots of multivariate effect sizes}
If a multivariate meta-analysis is conducted, pairwise plots on the pooled effect sizes and their confidence ellipses can be obtained via the \texttt{plot()} function. This plot is a multivarite generalization of the forest plot in univariate meta-analysis. By default, 95\% confidence intervals on the average effect sizes and confidence ellipses on the random effects are plotted \citep[see][]{Cheung:2011a}. Figure 1 shows the average effect sizes of the \texttt{Berkey98} example. The black dots and the black dashed ellipses are the observed effect sizes and their 95\% confidence ellipses in the primary studies. The blue square is the estimated average population effect sizes, while the red ellipse is the 95\% confidence ellipse of estimated population average effect sizes. This is a multivariate generalization of the average effect size and its 95\% confidence interval in univariate meta-analysis. The green ellipse is the 95\% confidence ellipse of the random effects. Ninty-five percent of the studies with average population effect sizes falls inside this confidence ellipse in long run. 
<<figure1, echo=TRUE, eval=TRUE, fig.cap="Plot of PD and AL", fig.width=5, fig.height=5, fig.pos="H", fig.align="center">>=
## Run the analysis again and save the object
my.fit <- meta(y=cbind(PD,AL),v=cbind(var_PD,cov_PD_AL,var_AL),
               data=Berkey98) 

## No main title and label the axes
plot(my.fit, main="", axis.label=c("PD","AL"))
@ 

% \begin{center}
%  \begin{figure}[H]
%    \includegraphics[scale=.7]{Figure1.pdf}
%   \caption{Plot of effect sizes and their confidence ellipses}  
% \end{figure}
% \end{center}

We may also combine the forest plots provided by the \texttt{metafor} package to provide more details on the individual effect sizes. Readers may understand both the univariate effects using the forest plot and the multivariate effects using the confidence ellipses. Figure 2 shows the confidence ellipses and the forest plots of the \texttt{Berkey98} example. 
<<figure2, message=FALSE, fig.cap="Plot of PD and AL with their forest plots", fig.pos="H", fig.align="center">>=
## Load the library for forest plots 
library("metafor")

## Create extra panels for the forest plots
plot(my.fit, diag.panel=TRUE, main="Multivariate meta-analysis",
axis.label=c("PD", "AL"))

## Forest plot for PD
forest( rma(yi=PD, vi=var_PD, data=Berkey98) )
title("Forest plot of PD")

## Forest plot for AL
forest( rma(yi=AL, vi=var_AL, data=Berkey98) )
title("Forest plot of AL")
@ 

% \begin{center}
%  \begin{figure}[H]
%    \includegraphics[scale=.7]{Figure2.pdf}
%   \caption{Plot of effect sizes, their confidence ellipses, and forest plots}  
% \end{figure}
% \end{center}

\subsubsection{Example 2}
The second example was based on the sixteen studies reported by \cite{aloe_classroom_2014}. These authors studied how the classroom management self-efficacy (CMSE) predicts the three dimensions of burnout. The effect sizes are the correlation coefficients between CMSE and emotional exhaustion (EE), depersonalization (DP), and (lowered) personal accomplishment (PA). Their sampling variances and covariances are labelled as \texttt{V\_xx} and \texttt{C\_xx\_yy} in the data set where \texttt{xx} and \texttt{yy} are either \texttt{EE}, \texttt{DP} or \texttt{PA}.

<<MMA0>>=
## Show the first few cases
head(Aloe14)
@ 

\paragraph{Random-effects model}
We may conduct a multivariate random-effects with the following syntax. The average effect sizes and their \textit{SE}s for \texttt{EE}, \texttt{DP}, and \texttt{PA} are -0.2805 (0.0302), -0.3262 (0.02823), and 0.4329 (0.0437), respectively. All the average effect sizes are statistically significant.
<<MMA1>>=
meta1 <- meta(y=cbind(EE,DP,PA), 
              v=cbind(V_EE, C_EE_PA, C_EE_PA, V_DP, C_DP_PA, V_PA),
              data=Aloe14)
summary(meta1)
@ 

We may extract and arrange the variance component for ease of inspection.
<<MMA2>>=
## Extract the variance component of the random effects
( coef1 <- coef(meta1, select="random") )

## Convert it into a symmetrix matrix by row major
my.cov <- vec2symMat(coef1, byrow=TRUE)

## Add the dimensions for ease of interpretation
dimnames(my.cov) <- list( c("EE", "DP", "PA"), 
                          c("EE", "DP", "PA") )
my.cov

## Convert it into a correlation matrix
( cov2cor(my.cov) )
@

The correlations among the random effects are extremely high. We may also visualize these correlations by the means of the confidence ellipses .
<<figure3, echo=TRUE, eval=TRUE, fig.cap="Plot of effect sizes and their confidence ellipses", fig.pos="H", fig.align="center">>=
## Plot the multivariate effect sizes
plot(meta1, main="", axis.labels=c("EE", "DP", "PA"))
@ 

% \begin{center}
%  \begin{figure}[H]
%    \includegraphics[scale=.7]{Figure3.pdf}
%   \caption{Plot of effect sizes and their confidence ellipses}  
% \end{figure}
% \end{center}

\paragraph{Mixed-effects model}
\cite{aloe_classroom_2014} tested several potential moderators. One of them was whether or not the studies are published in peer-reviewed journals. We may replicate the analysis with the following code.
<<MMA4>>=
## Create a variable on journal
( journal <- ifelse(Aloe14$Publication_type=="Journal", 1, 0) )


meta2 <- meta(y=cbind(EE,DP,PA), 
              v=cbind(V_EE, C_EE_PA, C_EE_PA, V_DP, C_DP_PA, V_PA),
              x=journal, data=Aloe14)
summary(meta2)
@ 
The estimated slopes on predicting and their \textit{SE}s for \texttt{EE}, \texttt{DP}, and \texttt{PA} are -0.0330 (0.0651), -0.0055 (0.0613), and 0.0620 (0.0907), respectively. All the slopes are non-significant. The $R^2$ for \texttt{EE}, \texttt{DP}, and \texttt{PA} are 0.01, 0.01, and 0.03, respectively.

We may also test the null hypothesis $\beta_\mathrm{EE}=\beta_\mathrm{DP}=\beta_\mathrm{PA}=0$ by comparing the models with and without the moderators with the following code. The  $\chi^2(df=3)=0.8338, p=0.8414$. Thus, the null hypothesis that both regression coefficients are zero is not rejected.
<<MMA5>>=
anova(meta2, meta1)
@ 

%% \subsubsection{Fixed-effects model}
%% For some unknown reasons, the FEM does not work.
%% <<MMA6>>=
%% summary( meta(y=cbind(EE,DP,PA), 
%%          v=cbind(V_EE, C_EE_PA, C_EE_PA, V_DP, C_DP_PA, V_PA),
%%          RE.constraints=matrix(0,nrow=3,ncol=3),
%%          data=Aloe14) )
%% @ 

\subsection{Three-level meta-analysis}
This data set, reported by \cite{konstantopoulos_fixed_2011} and \cite{cooper_effects_2003}, described fifty-six effect sizes clustered in 11 districts (\texttt{District}). The effect size is the standardized mean difference of the modified school calendar effectiveness. The \texttt{meta3()} function is used to fit three-level meta-analysis. 
<<meta3>>=
## Display the first few cases
head(Cooper03)
@ 


\subsubsection{Random-effects model}
The syntax of \texttt{meta3()} is very similar to that of \texttt{meta()} except that we need to specify the argument for \texttt{cluster}. For example,
<<meta3a>>=
summary( meta3(y=y, v=v, cluster=District, data=Cooper03) )
@ 

The analysis shows that the $Q(df=55) = 578.9, p<0.001$. The $I^2$ based on the $Q$ statistic at level 2 and level 3 are 0.34, and 0.60, respectively. These indicate that the studies (level 2) and the cluster (level 3) explain about 34\% and 60\% percentages of the total variation. There is only 6\% of the variation is due to sampling error. The average effect and its 95\% CI under a random-effects model is 0.1845 (0.0266, 0.3423). 
      
\subsubsection{Mixed-effects model}
We use \texttt{Year} of publication as a moderator. To make the intercept more meaningful, we may center the predictor. The estimated coefficient (and its 95\% Wald CI) of \texttt{Year} of publication in the following analysis is 0.0051 (-0.0116, 0.0218), which is not statistically significant. The $R^2$ at level 2 and level 3 are only 0.0000 and 0.0221, respectively.  
<<meta3b, echo=TRUE>>=
summary( meta3(y=y, v=v, cluster=District, 
               x=scale(Year, scale=FALSE), data=Cooper03) )
@ 

\subsection{Meta-analytic structural equation modeling} 
Two examples are used to illustrate how to use the TSSEM approach to fit structural equation models on the pooled correlation matrices.

\subsubsection{Example 1}
\cite{digman_higher-order_1997} reported a second-order factor analysis on a five-factor model with 14 studies. He suggested that there were two second-order factors on the five-factor model: an \textbf{Alpha} factor for \emph{agreeableness} \texttt{A}, \emph{conscientiousness} \texttt{C}, and \emph{emotional stability} \texttt{ES}, and a \textbf{Beta} factor for \emph{extroversion} \texttt{E} and \emph{intellect} \texttt{I}. We use the TSSEM approach to test the proposed model. This data set has been illustrated in several places \citep[e.g.,][]{cheung_classifying_2005, cheung_fixed-_2014, cheung_meta-analysis:_2015}. The correlation matrices and the sample sizes are stored in \texttt{Digman97\$data} and \texttt{Digman97\$n}, respectively. We may display the first few cases of the data set by calling the following commands in \textsf{R}.
<<Digman97_fixed1, echo=TRUE>>=
## Show the correlation matrices
head(Digman97$data)  

## Show the sample sizes
head(Digman97$n)         
@ 

\paragraph{Fixed-effects model: Stage 1 analysis}
The \texttt{tssem1()} function is used to pool the correlation matrices with a fixed-effects model in the first stage of the analysis by specifying \texttt{method="FEM"} in the argument: 
<<Digman97_fixed2, echo=TRUE>>=
fixed1 <- tssem1(Digman97$data, Digman97$n, method = "FEM")
summary(fixed1)
@ 
The fit indices for testing the homogeneity of the correlation matrices in the Stage 1 analysis are $\chi^2(df=130, N=4,496)=1,499.73, p <0.001$, CFI=0.68, TLI=0.66, SRMR=0.16, and RMSEA=0.18. These value indicate that it is not reasonable to assume that the correlation matrices are homogeneous. Rather, it would be more appropriate to employ a random-effects model that will be illustrated later. As an illustration, however, we continue to fit the stage 2 model even though the homogeneity assumption of the correlation matrices is questionable.

We may also extract the pooled correlation matrix by the following command.
<<Digman97_fixed2b, echo=TRUE>>=
coef(fixed1)
@ 

\paragraph{Stage 2 analysis}
The \texttt{tssem2()} function is then used to fit a factor analytic model on the pooled correlation matrix with the inverse of its asymptotic covariance matrix as the weight matrix. The structural model in the stage 2 analysis is specified via the reticular action model (RAM) formulation \citep{mcardle_algebraic_1984}. Structural models are specified via three matrices. \textbf{A} and \textbf{S} are used to specify the asymmetric paths and the symmetric variance covariance matrices, respectively. \textbf{A} denotes the asymmetric paths, such as the regression coefficients and the factor loadings among the variables, with $a_{ij}$ in \textbf{A} representing the regression coefficient from variable $j$ to variable $i$. \textbf{S} is a symmetric matrix representing the variances and covariances of the variables. It is used to specify the double arrows in path diagrams. The diagonal elements represent the variances of the variables. If the variables are independent variables, the corresponding diagonals in \textbf{S} denote the variances; otherwise, the corresponding diagonals in \textbf{S} represent the residuals of the dependent variables. The off-diagonals in \textbf{S} represent the covariances of the variables. \textbf{F} is a selection matrix used to filter observed variables. The following syntax specifies the \textbf{A} matrix:
<<Digman97_fixed3, echo=TRUE>>=
## Factor loadings
Lambda <-  matrix(c(".3*Alpha_A", ".3*Alpha_C", ".3*Alpha_ES",
                    rep(0,5),".3*Beta_E", ".3*Beta_I"), 
                  ncol = 2, nrow = 5)

## It is easier to create A this way since there are lots of 0
A1 <- rbind(cbind(matrix(0,ncol=5,nrow=5), Lambda), 
            matrix(0,ncol=7,nrow=2))

## This step is not necessary but is helpful in inspecting the content of A1. 
dimnames(A1) <- list(c("A", "C", "ES", "E", "I", "Alpha", "Beta"),
                     c("A", "C", "ES", "E", "I", "Alpha", "Beta"))
## Display the content of A1
A1                       
@ 

The above output shows the \textbf{A1} matrix. \texttt{Alpha\_A} is the label of the factor loading from \textbf{Alpha} to \textbf{A}, while "0.3" is the starting value. When the labels are the same, the parameters are constrained equally. The values of "0" mean that these factor loadings are fixed at 0. The following syntax specifies the \textbf{S} matrix:
<<Digman97_fixed4, echo=TRUE>>=
## Covariance matrix among the latent factors
Phi <- matrix(c(1, "0.3*cor", "0.3*cor",1), ncol=2, nrow=2)
## Error variances among the errors
Psi <- Diag(c(".2*e1", ".2*e2", ".2*e3", ".2*e4", ".2*e5"))

## Combine them to create the S matrix
S1 <- bdiagMat(list(Psi, Phi))

## This step is not necessary but is helpful in inspecting the content of S1. 
dimnames(S1) <- list(c("A", "C", "ES", "E", "I", "Alpha", "Beta"),
                     c("A", "C", "ES", "E", "I", "Alpha", "Beta"))
S1
@ 

The following syntax specifies the \textbf{F} matrix:
<<Digman97_fixed5, echo=TRUE>>=
## The first 5 variables are observed, whereas the last 2 are latent.
F1 <- create.Fmatrix(c(1, 1, 1, 1, 1, 0, 0), as.mxMatrix=FALSE)
## This step is not necessary but is helpful in inspecting the content of F1. 
dimnames(F1) <- list(c("A", "C", "ES", "E", "I"),
                     c("A", "C", "ES", "E", "I", "Alpha", "Beta"))                     
F1
@ 

We may then fit the structural model via the \texttt{tssem2()} command:
<<Digman97_fixed6, echo=TRUE>>=
fixed2 <- tssem2(fixed1, Amatrix=A1, Smatrix=S1, Fmatrix=F1, 
                 model.name="Digman97 FEM")
summary(fixed2)
@ 
The fit indices on the Stage 2 structural model are $\chi^2(df=4, N=4,496)=65.06, p <0.001$, CFI=0.98, TLI=0.95, SRMR=0.03, and RMSEA=0.06. Although the goodness-of-fit indices look good, we should be cautious when interpreting them because of the poor goodness-of-fit indices in the Stage 1 analysis.

\paragraph{Random-effects model: Stage 1 analysis}
The random-effects TSSEM may be requested by specifying the \texttt{method="REM"} argument in \texttt{tssem1()}. By default (\texttt{RE.type="Symm"}), a positive definite symmetric covariance matrix among the random effects is used. For practical reasons, such as an insufficient number of studies, it may not be feasible to estimate the full variance components of the random effects. A diagonal matrix of the random effects may be specified by using \texttt{RE.type="Diag"}. Researchers may also specify \texttt{RE.type="Zero"}. Since the variance component of the random effects is zero, the model becomes a fixed-effects model. This model is equivalent to the Generalized Least Squares (GLS) approach proposed by \citet{becker_using_1992}. 
<<Digman97_random1, echo=TRUE>>=
random1 <- tssem1(Digman97$data, Digman97$n, method="REM", RE.type="Diag")
summary(random1)
@ 

The $I^2$ indicates the heterogeneity of the correlation coefficients. For example, the following analysis shows that the $I^2$ based on the $Q$ statistic varies from 0.84 to 0.95, indicating a high degree of heterogeneity among the correlation elements. There is no goodness-of-fit indices for the random-effects TSSEM since it is usually based on a saturated model of mean vectors of fixed effects and variance components of random effects in a multivariate random-effects meta-analysis. 

If we want to extract the estimated average correlation matrix in matrix form, we may use the following command.
<<Digman97_random1b>>=
## Select the fixed effects and convert it into a correlation matrix
vec2symMat( coef(random1, select="fixed"), diag=FALSE )
@ 

\paragraph{Stage 2 analysis}
The Stage 2 analysis is conducted as usual via the \texttt{tssem2()} function. This functions automatically handles whether a fixed- or a random-effects model is used in the stage 1 analysis.
<<Digman97_random2, echo=TRUE>>=
random2 <- tssem2(random1, Amatrix=A1, Smatrix=S1, Fmatrix=F1)
summary(random2)
@
The fit indices on the Stage 2 structural model are $\chi^2(df=4, N=4,496)=8.51, p <0.001$, CFI=0.99, TLI=0.98, SRMR=0.05, and RMSEA=0.02. This indicates that the model fits the data quite well. The factor loadings on the \textbf{Alpha} factor are 0.5726, 0.5901, and 0.7705, while the factor loadings on the \textbf{Beta} factor are 0.6934, and 0.6401. The factor correlation between these two factors is 0.3937. All of these estimates are statistically significant. 

We may check whether the parameters are correctly labelled by displaying the model graphically. This helps us to check whether the theoretical model is the same as the fitted one.
<<figure4, fig.width=6, fig.height=6, fig.pos="H", fig.align="center">>=
## Library to plot the model
library("semPlot")

## Convert the model to semPlotModel object
## latNames: Names of the latent variables
my.plot <- meta2semPlot(random2, latNames=c("Alpha","Beta"))

## Plot the model with parameter labels
semPaths(my.plot, whatLabels="path", nCharEdges=10, nCharNodes=10, 
         color="yellow", edge.label.cex=0.8)
@

More importantly, we may plot the parameter estimates by the following command.
<<figure5, fig.width=6, fig.height=6, fig.pos="H", fig.align="center">>=
## Plot the parameter estimates
semPaths(my.plot, whatLabels="est", nCharNodes=10, color="green", 
         edge.label.cex=1.2)
@ 


\subsubsection{Example 2}
This dataset was based on \cite{becker_model-based_2009, craft_relationship_2003}. It includes ten studies of correlation matrices among \emph{Performance} \texttt{Per}, \emph{Cognitive} \texttt{Cog}, \emph{Somatic} \texttt{SO}, and \emph{Self confidence} \texttt{SC}. The dependent variable is \emph{Performance}, while the other variables are either independent variables or mediators.
<<Becker1>>=
## Display the first few cases of the data
head(Becker09$data)

## Display the sample sizes
Becker09$n
@ 

\paragraph{Fixed-effects model: Stage 1 analysis}
We may conduct the first stage analysis with a fixed-effects TSSEM with the following syntax. The fit indices for testing the homogeneity of the correlation matrices in the Stage 1 analysis are $\chi^2(df=46, N=633)=208.94, p <0.001$, CFI=0.72, TLI=0.68, SRMR=0.20, and RMSEA=0.24. These value indicate that it is not reasonable to assume that the correlation matrices are homogeneous.
<<Becker2>>=
## First stage analysis
fixed1 <- tssem1(Becker09$data, Becker09$n, method="FEM")
summary(fixed1)
@
\paragraph{Stage 2 analysis}
A random-effects model is preferred for this data set. As an illustration, we also fit the structural equation model in the stage two analysis. Since there are "mediators" in the model, the argument \texttt{diag.constraints=TRUE} must be specified. As there is no \texttt{SE} with the specification of the argument \texttt{diag.constraints=TRUE}, we may request the LBCI by specifying \texttt{intervals.type="LB"}.
<<Becker3>>=
## Regression coefficients
A1 <- create.mxMatrix(c(0, "0.1*Cog2Per", "0.1*SO2Per", "0.1*SC2Per",
                        0, 0, 0, 0,
                        0, 0, 0, 0,
                        0, "0.1*Cog2SC", "0.1*SO2SC",0),
                      type="Full", byrow=TRUE, ncol=4, nrow=4,
                      as.mxMatrix=FALSE)

## This step is not necessary but it is useful for inspecting the model.
dimnames(A1)[[1]] <- dimnames(A1)[[2]] <- c("Per","Cog","SO","SC") 

A1

## Covariance matrix among the variables
S1 <- create.mxMatrix(c("0.1*var_Per",
                        0, 1,
                        0, "0.1*cor", 1,
                        0, 0, 0, "0.1*var_SC"), byrow=TRUE, type="Symm",
                      as.mxMatrix=FALSE)

## This step is not necessary but it is useful for inspecting the model.
dimnames(S1)[[1]] <- dimnames(S1)[[2]] <- c("Per","Cog","SO","SC") 
S1

## Second stage analysis
fixed2 <- tssem2(fixed1, Amatrix=A1, Smatrix=S1, diag.constraints=TRUE,
                 intervals.type="LB")                 
## summary(fixed2)

## Rerun to clear the condition code
fixed2 <- rerun(fixed2, silent=TRUE)

summary(fixed2)
@ 

\paragraph{Fixed-effects model with subgroup analysis: Stage 1 analysis}
The above analysis indicates that the correlation matrices are very heterogeneous. This section illustrates how to group the studies into groups. If the studies become homogeneous, the grouping variable may be used to explain the heterogeneity.
<<Becker4>>=
## Display Type of sport
Becker09$Type_of_sport

cluster1 <- tssem1(Becker09$data, Becker09$n, method="FEM",
                   cluster=Becker09$Type_of_sport)
summary(cluster1)
@ 
The \textit{LR} statistics and the goodness-of-fit indicate that the correlation matrices are still heterogeneous. Grouping the studies does not help. 

\paragraph{Stage 2 analysis}
As an illustration, we still show how to conduct the stage two analysis though we are not going to interpret the results.
<<Becker5>>=
## Second stage analysis
cluster2 <- tssem2(cluster1, Amatrix=A1, Smatrix=S1, diag.constraints=TRUE,
                   intervals.type="LB")                 
summary(cluster2)
@ 

\paragraph{Plot the figures}
When there is a cluster variable, it is of interest to display the differences on the parameter estimates. We may use the following code to plot the models for the individual sport and the team sport.
<<figure6, fig.width=7, fig.height=7, fig.pos="H", fig.align="center">>=
## Convert the model to semPlotModel object with 2 plots
## Use the short forms of the variable names to simplify the figures
my.plots <- lapply(X=cluster2, FUN=meta2semPlot, 
                   manNames=c("Per","Cog","SO","SC") )

## Setup two plots
layout(t(1:2))
## The labels are overlapped. We may modify it by using layout="spring"
semPaths(my.plots[[1]], whatLabels="est", nCharNodes=10, 
         color="orange", layout="spring", edge.label.cex=0.8)
title("Individual sport")

semPaths(my.plots[[2]], whatLabels="est", nCharNodes=10, 
         color="skyblue", layout="spring", edge.label.cex=0.8)
title("Team sport")
@


\paragraph{Random-effects model: Stage 1 analysis}
We may conduct a random-effects TSSEM with the following syntax. Since there is not enough data, we restrict the structure of the variance component of the random effects by specifying \texttt{RE.type="Diag"}. The $I^2$ of the correlation coefficients varies from 0.00 to 0.90. A random-effects model is more appropriate than a fixed-effects model for this data set.
<<Becker6>>=
## First stage analysis
random1 <- tssem1(Becker09$data, Becker09$n, method="REM", 
                  RE.type="Diag")
summary(random1)
@ 

\paragraph{Stage 2 analysis}
Since the model is a saturated model, the \textit{LR} statistic is 0 with 0 \textit{df}. When there are mediators, we may also want to estimate the indirect effects. The \texttt{tssem2()} function allows us to include arbitrary algebras. For example, we may define the indirect effects via \texttt{Cog} and \texttt{SO} separately and totally with the following syntax. LBCI on these values may also be obtained. The results show that the indirect effects via \texttt{Cog} and \texttt{SO} separately and totally are -0.1075, -0.1099 and -0.2174, respectively. All of these effects are statistically significant.
<<Becker8>>=
## Second stage analysis
random2 <- tssem2(fixed1, Amatrix=A1, Smatrix=S1, diag.constraints=TRUE,
                  intervals.type="LB", model.name="TSSEM2 Becker09",
            mx.algebras=list( Cog=mxAlgebra(Cog2SC*SC2Per, name="Cog"), 
                              SO=mxAlgebra(SO2SC*SC2Per, name="SO"),
                              Cog_SO=mxAlgebra(Cog2SC*SC2Per+SO2SC*SC2Per,
                              name="Cog_SO")) )                 
summary(random2)
@ 

We may plot the model and label the parameters for checking.
<<figure7, fig.cap="Plot of parameter labels", fig.width=7, fig.height=7, fig.pos="H", fig.align="center">>=
## Convert the model to semPlotModel object
my.plot <- meta2semPlot(random2, manNames=c("Per","Cog","SO","SC") )

## Plot the model with labels
## The labels are overlapped. We may modify it by using layout="spring"
semPaths(my.plot, whatLabels="path", nCharEdges=10,  nCharNodes=10, 
         layout="spring", color="yellow", edge.label.cex=0.8)
@

We may also plot the parameter estimates in the figure.
<<figure9, fig.cap="Plot of parameter labels", fig.width=7, fig.height=7, fig.pos="H", fig.align="center">>=
## Plot the parameter estimates
semPaths(my.plot, whatLabels="est", nCharNodes=10, layout="spring", 
         color="green", edge.label.cex=1.2)
@

The above analyses were conducted based on the following \texttt{R} Packages.
<<>>=
sessionInfo()
@ 


\section{Conclusion} 
This paper introduced various meta-analytic models using a SEM approach. More importantly, these models have all been implemented in the \texttt{metaSEM} package which is freely available as an \R{} package. Due to space constraint, I did not include topics, such as using REML as the estimation method \citep[see][]{Cheung:2013a}, constructing likelihood-based confidence interval (LBCI) \cite[see][]{Cheung:2009a}, and using alternative random-effects MASEM \cite[see][]{cheung_random_2014}. Readers may refer to the relevant papers and the \texttt{metaSEM} package for details. Some of these models can be implemented in standard SEM software such as M\textit{plus} \citep{muthen_mplus_2012}. Since SEM software was not designed for meta-analysis, transformations on the effect sizes are required to meet the distribution assumptions \citep[see e.g.,][]{Cheung:2008, Cheung:2011a}. To conclude, SEM provides a flexible framework to develop meta-analytic techniques. Many of the techniques available in SEM can be easily extended to meta-analysis. The supplementary material include some examples on how to analyze these models using the \texttt{metaSEM} package.


\bibliographystyle{apalike} % for Science and Engineering articles
%\bibliographystyle{frontiersinHLTH&FPHY} % for Health and Physics articles
\bibliography{metaSEM}

\end{document}
